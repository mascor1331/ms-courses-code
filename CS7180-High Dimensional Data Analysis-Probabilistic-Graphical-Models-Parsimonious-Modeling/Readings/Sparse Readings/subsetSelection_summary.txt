Finding an informative subset of a large collection of data points or models is at the center of many problems in computer vision, recommender systems, bio/health informatics as well as image and natural language processing. Given pairwise dissimilarities between the elements of a ‘source set’ and a ‘target set,’ we consider the problem of finding a subset of the source set, called representatives or exemplars, that can efficiently describe the target set. We formulate the problem as a row-sparsity regularized trace minimization problem. Since the proposed formulation is, in general, NP-hard, we consider a convex relaxation. The solution of our optimization finds representatives and the assignment of each element of the target set to each representative, hence, obtaining a clustering. We analyze the solution of our proposed optimization as a function of the regularization parameter. We show that when the two sets jointly partition into multiple groups, our algorithm finds representatives from all groups and reveals clustering of the sets. In addition, we show that the proposed framework can effectively deal with outliers. Our algorithm works with arbitrary dissimilarities, which can be asymmetric or violate the triangle inequality. To efficiently implement our algorithm, we consider an Alternating Direction Method of Multipliers (ADMM) framework, which results in quadratic complexity in the problem size. We show that the ADMM implementation allows to parallelize the algorithm, hence further reducing the computational time. Finally, by experiments on real-world datasets, we show that our proposed algorithm improves the state of the art on the two problems of scene categorization using representative images and time-series modeling and segmentation using representative models. 

Given pairwise dissimilarities between a source and a target set, we considered the problem of finding representatives from the source set that can efficiently encode the target set. We proposed a row-sparsity regularized trace minimization formulation, which can be solved efficiently using convex programming. We showed that our algorithm has theoretical guarantees in that when there is a joint grouping of sets, our method finds representatives from all groups and reveals the clustering of the sets. We also investigated the effect of the regularization parameter on properties of the obtained solution. We provided an efficient implementation of our algorithm using an ADMM approach and showed that our implementation is highly parallelizable, hence further reducing the computational time. Finally, by experiments on real datasets, we showed that our algorithm improves the state of the art on the problems of scene categorization using representative images and modeling and segmentation of time- series data using representative models. Our ongoing research work includes scaling the DS3 algorithm to very large datasets, investigating theoretical guarantees of our algorithm in high- dimensional statistical settings and a more in-depth study of the properties of DS3 when dealing with outliers. 

In this paper, authors propose a novel way of finding a compressed subset that represents its corresponding larger dataset correctly. By taking the dissimilarity-based sparse subset selection (DS3) of original dataset, problem is posed as a row-sparsity regularized trace minimization formulation which is solved using recent advances in convex optimzation since it is a computationally intractable. DS3 is guaranteed to find representative and clusters of sets when the sets jointly partition in separate groups. The regularization parameter acts as a trade-off between number of clusters and penalizing the encoding cost. Implementation of DS3 using alternative direction method multiplier lends to parallelism which is highly suitable for modern data distributed environments. Another induced feature due to convex optimization is the robustness towards disparities and outliers in the data (outlier would lie in too many clusters hence identifying themselves). Evaluating the algorithm in comparision with Affinity Propagation, Kmedoids, and random selection (Rand) as the baseline on problems of nearest neighbor (NN) classification using representative samples and dynamic data modeling and segmentation using representative models on two real different datasets show that the algorithm performs on par with current state of art algorithms helping NN in speeding clustering and even increase accuracy as the number of training samples per class increase. Also, proposed solution deals with temporal data and results into manifold accuracy increase compared to other algorithms dependent on graph partitioning. Future work involves investigating whether the theorectical claims stand true in case of very large datasets and robustness to various outliers.

